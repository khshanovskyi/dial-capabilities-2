<h1 align="center">
         DIAL Platform Capabilities Presentation (Part 2)
    </h1>
    <p align="center">
        <p align="center">
        <a href="https://dialx.ai/">
          <img src="https://dialx.ai/dialx_logo.svg" alt="About DIALX">
        </a>
    </p>
<h4 align="center">
    <a href="https://discord.gg/ukzj9U9tEe">
        <img src="https://img.shields.io/static/v1?label=DIALX%20Community%20on&message=Discord&color=blue&logo=Discord&style=flat-square" alt="Discord">
    </a>
</h4>


- [1. Add Agent](#1-Add-Agent)
- [2. Add Agent](#2-QuickApps--MCP-toolsets)
  - [2.1 Agent sample with QuickApps](#21-Agent-sample-with-QuickApps)
  - [2.2 QuickApps Agent with several toolsets (GitHub, Notion)](#22-QuickApps-Agent-with-several-toolsets-GitHub-Notion)
- [3. Interceptors](#3-Interceptors)
  - [3.1 Pre/Post Interceptor Sample](#31-PrePost-Interceptor-Sample)
  - [3.2 Talk as a Pirate](#32-Talk-as-a-Pirate)
  - [3.3 Statistics Reporter](#33-Statistics-Reporter)
  - [3.4 Image watermark](#34-Image-watermark)
  - [3.5 PII Anonymizer](#35-PII-Anonymizer)
- [3. Custom Themes](#4-Custom-Themes)
- [5. Chat Overlay](#5-Chat-Overlay)

---

## 1. Add Agent

Now let's add simple Agent that will have several tools:
- Image generation tool
- Essay Assistant to generate essays
- Additionally, we will convert to speech generated by LLM final output.
All the tools are the DIAL Deployment tools, we will take a look how with the one interface we can communicate with models and applications within DIAL Platform.

![agent](app_demo/d2_simple_agent/_flow.png)

1. Add to [core/config.json](core/config.json) to **applications** section:
    ```
        "agent-sample": {
          "displayName": "Agent Sample",
          "description": "Simple Agent, that is able to make RAG, generate Essays and Pictures, and provides final output converted to speech",
          "endpoint": "http://host.docker.internal:5030/openai/deployments/agent-sample/chat/completions"
        }
    ```
2. Add to [core/config.json](core/config.json) to **models** section:
    DALL-E for image generation
    ```
        "dall-e-3": {
          "type": "chat",
          "endpoint": "http://adapter-dial-openai:5000/openai/deployments/dall-e-3/chat/completions",
          "overrideName": "dall-e-3",
          "upstreams": [
            {
              "endpoint": "https://api.openai.com/v1/images/generations",
              "key": "${OPENAI_API_KEY}"
            }
          ]
        }
    ```
   TTS to convert final response from orchestration model to audio
    ```
        "gpt-4o-mini-tts": {
          "type": "chat",
          "endpoint": "http://adapter-dial-openai:5000/openai/deployments/gpt-4o-mini-tts/chat/completions",
          "overrideName": "gpt-4o-mini-tts",
          "upstreams": [
            {
              "endpoint": "https://api.openai.com/v1/audio/speech",
              "key": "${OPENAI_API_KEY}"
            }
          ]
        }
    ```
3. Replace ${OPENAI_API_KEY} with your OpenAI API Key
4. Add to `adapter-dial-openai` in [docker-compose](docker-compose.yml) such env variable:
   - DALLE3_DEPLOYMENTS: dall-e-3
5. Run the [d1_essay_assistant/app_gpt.py](app_demo/d1_essay_assistant/app_gpt.py) with Essay assistant app
6. Run the [agent_app.py](app_demo/d2_simple_agent/agent_app.py)
7. Restart whole docker compose
8. Test it
    ```
    hi, what can you do?
    ```
    ```
    Generate an essay about an elephant that loves to paint, then, based on the essay, generate a picture
    ```


<details><summary>Result samples</summary>

![Agent Marketplace](screenshots/agent-sample-marketplace.png)
![Agent result 1](screenshots/agent-result-1.png)
![Agent result 2](screenshots/agent-result-2.png)

</details>

---

## 2. QuickApps + MCP toolsets

> **For now QuickApps are not in opensource, so you won't be able to reproduce flow from this section!**


QuickApps is a composer for building DIAL applications from reusable tools and integrations. 
It lets you declaratively compose new DIAL applications by wiring DIAL-native tools, REST APIs, and MCP servers with any
LLM registered in DIAL Core acting as the orchestrator. Publishing a Quick App produces a DIAL application record managed by Core.

### 2.1 Agent sample with QuickApps

> In this section we will create similar Agent sample as we've done in the [1st section](#1-add-agent) without writing any code

<details><summary>Configuration flow</summary>

1. In [workspace](http://localhost:3000/marketplace?tab=workspace) choose `Add app` and choose `Quick App 2.0`
    ![-](screenshots/qa-config-1.png)
2. Provide name and description and click `Next`
   ![-](screenshots/qa-config-2.png)
3. In `Agents & Toolsets` section choose `Essay Assistant` with `sonnet-4` version and `dall-e-3` deployments, click `Configure`
   ![-](screenshots/qa-config-4.png)
4.  In `Instructions` section insert this system prompt and `Save and close`:
    ```text
    ## Core Identity
    You are an intelligent AI assistant that solves problems through careful reasoning and strategic use of specialized tools. You have access to multiple tools that extend your capabilities beyond text generation.
    
    ## Problem-Solving Approach
    
    When handling user requests, follow this reasoning process internally:
    
    1. **Understand the request:** What is the user asking for? What's the core problem?
    2. **Assess your knowledge:** What do you know? What information is missing?
    3. **Plan your approach:** Which tools would help? In what order?
    4. **Explain your reasoning:** Before using tools, briefly explain WHY you're using them
    5. **Interpret results:** After getting tool outputs, explain what you learned and how it helps
    6. **Synthesize:** Combine all information into a complete, helpful answer
    
    ## Important Rules
    
    - **Never print URLs** of generated files directly in your response
    - **Always explain a reason** before calling a tool (brief, 1-2 sentences)
    - **Always interpret results** after receiving tool outputs
    - **Be efficient:** Don't over-explain simple requests, but show reasoning for complex ones
    - **Natural flow:** Your reasoning should feel like part of the conversation, not a formal structure
    
    ## Quality Standards
    
    A good response:
    - Explains the approach before taking action
    - Uses tools strategically and purposefully  
    - Interprets results in context of the user's question
    - Provides a complete, well-reasoned answer
    
    A poor response:
    - Calls tools without explanation
    - Ignores tool results without interpretation
    - Uses formal labels like "Thought:" or "Action:"
    - Provides disconnected or mechanical responses
    
    ---
    
    *Remember: Be helpful, transparent, and strategic. Users should understand your reasoning without seeing formal structures.*
    ```
    ![-](screenshots/qa-config-5.png)
5. Your Agent is ready for usage, just click `Use application`
   ![Agent Marketplace](screenshots/qa-use-app.png)
6. Test it:
    ```
    hi, what can you do?
    ```
    ```
    Generate an essay about an elephant that loves to paint, then, based on the essay, generate a picture
    ```
   ![-](screenshots/qa-use-app-1.png)
   ![-](screenshots/qa-use-app-2.png)
   ![-](screenshots/qa-use-app-3.png)
   ![](screenshots/qa-use-app-4.png)
   ![-](screenshots/qa-ts-add.png)

> **Easy, right? For now to create an Agent you don't have to know how to write the code, you can configure one through DIAL Chat with deployments and toolsets available in your workspace**

</details>

---

### 2.2 QuickApps Agent with several toolsets (GitHub, Notion)

> In this section we will Agents that will work with GitHub and Notion. We will configure toolsets that will work with remote MCP servers for these services


<details><summary>GitHub Agent configuration flow</summary>

1. In [workspace toolsets](http://localhost:3000/marketplace?tab=workspace&entitiesTab=toolsets) click `Add toolset`
   ![-](screenshots/qa-ts-add.png)
2. Provide name and description and click `Next`
   ![-](screenshots/qa-ts-1.png)
3. Endpoint: `https://api.githubcopilot.com/mcp/`, Transport protocol: `HTTP`, Authentication: `API Key`. Then provide auth header and token. Token you can generate here ðŸ‘‰ https://github.com/settings/tokens. Then click `Log in` 
   ![-](screenshots/qa-ts-2.png)
4.  Click `Save and close`:
    ![-](screenshots/qa-ts-3.png)
5. In [workspace](http://localhost:3000/marketplace?tab=workspace) choose `Add app` and choose `Quick App 2.0`
      ![-](screenshots/qa-ts-add-qa.png)
6. Provide name and description and click `Next`
   ![-](screenshots/qa-ts-5.png)
7. In `Agents & Toolsets` section choose `GitHub Toolset` toolset and click `Configure`
   ![-](screenshots/qa-ts-6.png)
8. In `Instructions` section insert this system prompt and `Save and close`:
    ```
    You are GitHub agent. Your goal is to help me with tasks related to GitHub
    ```
   ![-](screenshots/qa-ts-7.png)
9. Your Agent is ready for usage, just click `Use application`
10. Test it with:
    ```
    What tools do you have (name and description)
    ```
    ```
    what branches the `dial-capabilities-1` project from khshanovskyi has?
    ```
    ![-](screenshots/qa-ts-8.png)
    ![-](screenshots/qa-ts-9.png)

</details>

<details><summary>Notion Agent configuration flow</summary>

1. In [workspace toolsets](http://localhost:3000/marketplace?tab=workspace&entitiesTab=toolsets) click `Add toolset`
   ![-](screenshots/qa-ts-add.png)
2. Provide name and description and click `Next`
   ![-](screenshots/qa-ts-n-1.png)
3. Endpoint: `https://mcp.notion.com/mcp`, Transport protocol: `HTTP`, Authentication: `OAuth`. Then click `Log in` and allow toolsets connect to Notion
   ![-](screenshots/qa-ts-n-2.png)
   ![-](screenshots/qa-ts-n-3.png)
4.  Click `Save and close`:
    ![-](screenshots/qa-ts-n-4.png)
5. In [workspace](http://localhost:3000/marketplace?tab=workspace) choose `Add app` and choose `Quick App 2.0`
   ![-](screenshots/qa-ts-add-qa.png)
6. Provide name and description and click `Next`
   ![-](screenshots/qa-ts-n-5.png)
7. In `Agents & Toolsets` section choose `Notion roolset` toolset and click `Configure`
   ![-](screenshots/qa-ts-n-6.png)
8. In `Instructions` section insert this system prompt and `Save and close`:
    ```
    You are Notion Agent. Your goal is to help me with tasks with Notion
    ```
   ![-](screenshots/qa-ts-n-7.png)
9. Your Agent is ready for usage, just click `Use application`
10. Test it with:
    ```
    What tools do you have (name and description)
    ```
    ```
    Create page with name `DIAL Capabilities` with content inside `Hello from DIAL Toolsets and QuickApps`
    ```
    ![-](screenshots/qa-ts-n-8.png)
    ![-](screenshots/qa-ts-n-9.png)
    ![-](screenshots/qa-ts-n-10.png)
    ![-](screenshots/qa-ts-n-11.png)

</details>

---

## 3. Interceptors

Interceptors can be seen as a middleware that modifies incoming or outgoing requests according to a specific logic. In DIAL, we use interceptors to facilitate the implementation of a so-called Responsible AI approach and enforce compliance with internal and external privacy regulations and policies.

Interceptors could be classified into the following categories:
- **Pre-interceptors** that only modify the incoming request from the client (e.g. rejecting requests following certain criteria)
- **Post-interceptors** that only modify the response received from the upstream (e.g. censoring the response)
- **Generic interceptors** that modify both the incoming request and the response from the upstream (e.g. caching the responses)

[Read more in documentation about DIAL Interceptors](https://docs.dialx.ai/platform/core/interceptors)

Also, DIAL provides [DIAL Interceptors Python SDK](https://github.com/epam/ai-dial-interceptors-sdk/tree/development) that helps to build interceptors

### 3.1 Pre/Post Interceptor Sample

Let's try to add our first simple interceptor that will create a stage with greetings before accessing deployment, and will create Goodbye Stage after deployment finished with response:
1. Add to [core/config.json](core/config.json) to **interceptors** section:
    ```
        "chat-pre-post-interceptor": {
          "endpoint": "http://host.docker.internal:5041/openai/deployments/pre-post-interceptorchat/completions"
        }
    ```
2. Add this `"chat-in-out-interceptor"` to the `essay-assistant-gpt` application in `interceptors` array:

    Full config `essay-assistant-gpt` with interceptor:
    ```
        "essay-assistant-gpt": {
          "displayName": "Essay Assistant",
          "displayVersion": "gpt-4o",
          "description": "Essay Assistant. Always answers with essay.",
          "endpoint": "http://host.docker.internal:5025/openai/deployments/essay-assistant-gpt/chat/completions",
          "features": {
            "configurationEndpoint": "http://host.docker.internal:5025/openai/deployments/essay-assistant-gpt/configuration"
          },
          "interceptors": [
            "chat-pre-post-interceptor"
          ]
        }
    ```
3. Run the [d1_essay_assistant/app_gpt.py](app_demo/d1_essay_assistant/app_gpt.py) with Essay Assistant (GPT) app
4. Run the [i1_pre_post_interceptor_sample.py](app_demo/d3_interceptors/i1_pre_post_interceptor_sample.py) with PrePostInterceptorSample app
5. Restart DIAL Core
6. Test it in DIAL Chat ðŸ‘‰ http://localhost:3000/

<details><summary>Result samples</summary>

![Essay GPT](screenshots/essay-app.png)
![Essay GPT pre/post start](screenshots/essay-gpt-pre-post-start.png)
![Essay GPT pre/post finish](screenshots/essay-gpt-pre-post-finish.png)

</details>

---

### 3.2 Talk as a Pirate

We can inject our own messages into `messages` from request. Let's inject system prompt that will push model to generate response as pirate:
1. Add to [core/config.json](core/config.json) to **interceptors** section:
    ```
        "chat-reply-as-pirate": {
          "endpoint": "http://host.docker.internal:5042/openai/deployments/reply-as-pirate/chat/completions"
        }
    ```
2. Add to [core/config.json](core/config.json) to **models** section:
    ```
        "gpt-4o-pirate": {
          "displayName": "GPT 4o Pirate",
          "overrideName": "gpt-4o",
          "endpoint": "http://adapter-dial-openai:5000/openai/deployments/gpt-4o/chat/completions",
          "iconUrl": "http://localhost:3001/gpt4.svg",
          "type": "chat",
          "upstreams": [
            {
              "endpoint": "https://api.openai.com/v1/chat/completions",
              "key": "${YOUR_OPENAI_API_KEY}"
            }
          ],
          "interceptors": [
            "chat-reply-as-pirate"
          ]
        }
    ```
3. Replace `${YOUR_OPENAI_API_KEY}` with your OpenAI API Key
4. Run the [i2_pirate_interceptor.py](app_demo/d3_interceptors/i2_pirate_interceptor.py)
5. Restart DIAL Core
6. Test it in DIAL Chat

<details><summary>Result samples</summary>

![GPT Pirate 1](screenshots/gpt-pirate-1.png)
![GPT Pirate 2](screenshots/gpt-pirate-2.png)

</details>

---

### 3.3 Statistics Reporter

We can collect some statistics from deployments response, lets add `statistics-reporter` to `gpt-4o-pirate` model:

1. Add to [core/config.json](core/config.json) to **interceptors** section:
    ```
        "chat-statistics-reporter": {
          "endpoint": "http://host.docker.internal:5043/openai/deployments/statistics-reporter/chat/completions"
        },
    ```
2. Add to [core/config.json](core/config.json) to `gpt-4o-pirate` model the `"chat-statistics-reporter"` into interceptors array
3. Run the [i3_statistics_interceptor.py](app_demo/d3_interceptors/i3_statistics_interceptor.py)
4. Restart DIAL Core
5. Test it in DIAL Chat

<details><summary>Result samples</summary>

![GPT Pirate 1](screenshots/gpt-pirate-1.png)
![GPT Pirate 2](screenshots/gpt-pirate-statistics.png)

</details>

---

### 3.4 Image watermark

Now, let's take a look at one more Post-Interceptor that will add watermark to the generated image:
We can inject our own messages into `messages` from request. Let's inject system prompt that will push model to generate response as pirate:
1. Add to [core/config.json](core/config.json) to **interceptors** section:
    ```
        "chat-image-watermark": {
          "endpoint": "http://host.docker.internal:5044/openai/deployments/image-watermark/chat/completions"
        }
    ```
2. Add to [core/config.json](core/config.json) `dall-e-3` model `chat-image-watermark` interceptor
3. Run the [i4_image_watermark.py](app_demo/d3_interceptors/i4_image_watermark.py)
4. Restart DIAL Core
5. Test it in DIAL Chat

<details><summary>Result samples</summary>

![DALL-E watermarked](screenshots/dalle-watermarked.png)

</details>

---

### 3.5 PII Anonymizer

Now, let's take at more real case where we can use interceptors. Many companies are concerned of leakage of PII 
(Personally Identifiable Information) of their clients or employees. Usually we fix it with special guardrails
(input or output) in code, and to do that we usually provide additional steps in code. 
With DIAL Interceptors it is much easier to do since you can create Interceptor for some specific task and then apply 
it to any deployments.

Now, let's add simple PII anonymizer, it is Generic (Pre+Post) Interceptor, but pay attention that sometimes Post part is not revering back anonymized data normally:

Now, let's take a look at one more Post-Interceptor that will add watermark to the generated image:
We can inject our own messages into `messages` from request. Let's inject system prompt that will push model to generate response as pirate:
1. Add to [core/config.json](core/config.json) to **interceptors** section:
    ```
        "chat-pii-anonymizer": {
          "endpoint": "http://host.docker.internal:5045/openai/deployments/pii-anonymizer/chat/completions"
        }
    ```
2. Add to [core/config.json](core/config.json) `agent-sample` application `chat-pii-anonymizer` interceptor
3. Run the [i5_pii_anonymizer.py](app_demo/d3_interceptors/i5_pii_anonymizer.py)
4. Run the [d2_simple_agent/agent_app.py](app_demo/d2_simple_agent/agent_app.py)
5. Restart DIAL Core
6. Test it in DIAL Chat
    ```
    List the salaries in a table in descending:
    
    Michael Chen salary is 7200, date of join 2022-01-10.
    Emily Rodriguez salary is 6200, date of join 2020-06-18.
    David Thompson salary is 8300K, date of join 2018-11-05.
    ```

<details><summary>Result samples</summary>

![Agent PII 1](screenshots/agen-pii-1.png)
![Agent PII 1](screenshots/agen-pii-2.png)
![Agent PII 1](screenshots/agen-pii-3.png)

</details>

---

## 4. Custom Themes

You can modify Chat Themes. See detailed instructions in [DIAL Chat Themes repository](https://github.com/epam/ai-dial-chat-themes?tab=readme-ov-file#overview). 

[Here more detailed instruction about Chat UI configuration](https://github.com/epam/ai-dial/blob/main/docs/tutorials/1.developers/3.chat/3.chat-design.md)

Let's add Pink Theme to our chat:
1. Add to docker compose mount to [new themes config.json](app_demo/d4_themes/config.json):
    ```yaml
        volumes:
          - ./app_demo/d4_themes/config.json:/var/www/config.json:ro
    ```
    Final service setup:
    ```yaml
      themes:
        image: epam/ai-dial-chat-themes:development
        platform: linux/amd64
        ports:
          - "3001:8080"
        volumes:
          - ./app_demo/d4_themes/config.json:/var/www/config.json:ro
    ```
2. Delete `themes` container and start it again
3. Restart `chat` service
4. Test it: Click `User` -> `Setting` -> choose `Pink` Theme 

<details><summary>Result samples</summary>

![Theme 1](screenshots/theme-1.png)
![Theme 2](screenshots/theme-2.png)
![Theme 3](screenshots/theme-3.png)

</details>

---

## 5. Chat Overlay

We integrate DIAL Chat into other applications with C[hat Overlay](https://docs.dialx.ai/platform/architecture-and-concepts/components#overlay)

1. Set env variables to `chat` service in [docker-compose.yml](docker-compose.yml):
   - IS_IFRAME: true
   - ALLOWED_IFRAME_ORIGINS: http://localhost:5173/
2. Run in terminal `npm create vite@latest overlay-app` and choose options bellow:
   - project **Vanilla**
   - **js** (not ts)
   - **no** (just create project and that is all)
   After that you should be able to see the `overlay-app` folder [overlay-app](overlay-app)
3. Run in terminal `cd overlay-app`
4. Run in terminal `npm i` (to install base dependencies) 
5. Run in terminal `npm i @epam/ai-dial-overlay` (to install DIAL overlay library)
6. Replace content in `overlay-app.src/main.js` [main.js](overlay-app/src/main.js) to:
    ```js
    import './style.css'
    import { ChatOverlay } from "@epam/ai-dial-overlay";
    
    document.querySelector('#app').innerHTML = `
      <div>
        <h1>OVERLAY</h1>
      </div>
    `
    
    const container = document.createElement("div");
    container.style.width = "400px";
    container.style.height = "600px";
    document.querySelector('#app').appendChild(container);
    
    const run = async () => {
      const overlay = new ChatOverlay(container, {
        hostDomain: window.location.origin,
        domain: "http://localhost:3000",
        requestTimeout: 20000,
        enabledFeatures: [
          "conversations-section",
          "prompts-section",
          "top-settings",
          "top-clear-conversation",
          "top-chat-info",
          "top-chat-model-settings",
          "empty-chat-settings",
          "header",
          "footer",
          "request-api-key",
          "report-an-issue",
          "likes",
        ],
        loaderStyles: {
          background: "black",
        },
      });
    
      await overlay.ready();
    };
    
    run();
    ```
7. Run in terminal `npm run dev` (to run overlay app)
8. Delete `chat` container and run it again (to fetch new env variables)
9. Open http://localhost:5173/ in browser and test it

<details><summary>Result samples</summary>

![Theme 1](screenshots/overlay-sample.png)

</details>

---

## 6.

---

## DON'T FORGET TO DELETE API KEYS BEFORE PUSH
